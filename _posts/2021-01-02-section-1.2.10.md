---
layout: post
title: "section-1.2.10"
date: 2021-01-02 15:26:16 -0700
categories: taobataocp
---

This section is a doozy.

The first chunk is about analyzing the running time of a simple algorithm to find the max of an array.  For some reason, he iterates through the array backwards, maybe so that the termination check is k==0 which is "nice?"  Also, the algorithm is written using "goto" form.

Something that I remember sticking out from when I read this section years ago is that when you draw the algorithm as a flow chart, the number of "incoming edges" to a step has to be the same as the number of "outgoing edges" which he relates to Kirchoff's current law from electronics.

The next chunk is about analyizing how many times the max value is updated in the loop, assuming that the array contains no duplicates and each permutation is equally likely.  I was sort of surprised that the average number of swaps when the array is length 3 is 5/6 (less than 1).  You have to swap at least once for 2/3 of the permutations, but the #swaps/#permutations is less than 1 which still seems weird.

The next part uses a generating function on probablities to compute the expected number of swaps and its variance.  There's some cleverness that he does by taking derivatives of the generating function to get nice expressions for the mean/varaiance.

I don't think I ever used generating functions for analysis, even in my grad level algorithms class at UBC, so it's an interesting perspective for analysis.  It feels like the stuff we studied was simple enough that we didn't need that tool?